# caret
# https://cran.r-project.org/web/packages/caret/vignettes/caret.html
install.packages("caret", dependencies = c("Depends", "Suggests"))

library(caret)
library(mlbench)
data(Sonar)
head(Sonar)

set.seed(107)
inTrain <- createDataPartition(
  y = Sonar$Class,
  ## the outcome data are needed
  p = .75,
  ## The percentage of data in the
  ## training set
  list = FALSE
)
## The format of the results

## The output is a set of integers for the rows of Sonar
## that belong in the training set.
head(inTrain)

str(inTrain)
training <- Sonar[ inTrain,]
testing  <- Sonar[-inTrain,]

nrow(training)
nrow(testing)

plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  ## Center and scale the predictors for the training
  ## set and all future samples.
  preProc = c("center", "scale")
)


ctrl <- trainControl(
  method = "repeatedcv",
  repeats = 3,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)
head(ctrl)

set.seed(123)
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  trControl = ctrl,
  metric = "ROC"
)
plsFit


ggplot(plsFit)

plsClasses <- predict(plsFit, newdata = testing)
str(plsClasses)
head(plsClasses)
plsProbs <- predict(plsFit, newdata = testing, type = "prob")
head(plsProbs)

head(plsClasses)
length(plsClasses)
head(testing$Class)
length(testing$Class)

confusionMatrix(data = plsClasses, testing$Class)
confusionMatrix()

# 1. glowna tabela
dane <- data.frame(
             CPC2 = sample(c(0,1), replace=TRUE, size=1000),
             PLEK = sample(c(0,1), replace=TRUE, size=1000),
             CPAT = sample(c(0,1), replace=TRUE, size=1000),
             Feelnc = sample(c(0,1), replace=TRUE, size=1000),
             MDeep = sample(c(0,1), replace=TRUE, size=1000),
             CNCI = sample(c(0,1), replace=TRUE, size=1000),
             lncFinder = sample(c(0,1), replace=TRUE, size=1000),
             lnc = sample(c(0,1), replace=TRUE, size=1000)
             )
head(dane)
rownames(dane) <- paste0("gen_", 1:1000)

CodPot_res_tab <- dane[,1:7]
confirmed_lnc <- dane$lnc
n_methods <- ncol(dane)-1


# 2. co najmniej n
for (n in 1:n_methods) {
  CodPot_res_tab[,paste0("at_least_",n)] <- ifelse(rowSums(dane) >= n, 1, 0)
}

# 3. wszystkie kombinacje z venna - do zrobienia
library(gplots)
library(venn)
ven <- venn(list(
  CPC2 = rownames(dane[dane$CPC2 %in% 1,]),
  PLEK = rownames(dane[dane$PLEK %in% 1,]),
  CPAT = rownames(dane[dane$CPAT %in% 1,]),
  Feelnc = rownames(dane[dane$Feelnc %in% 1,]),
  MDeep = rownames(dane[dane$MDeep %in% 1,]),
  CNCI = rownames(dane[dane$CNCI %in% 1,])
))

lista <- list(
  CPC2 = rownames(dane[dane$CPC2 %in% 1,]),
  PLEK = rownames(dane[dane$PLEK %in% 1,]),
  CPAT = rownames(dane[dane$CPAT %in% 1,]),
  Feelnc = rownames(dane[dane$Feelnc %in% 1,]),
  MDeep = rownames(dane[dane$MDeep %in% 1,]),
  CNCI = rownames(dane[dane$CNCI %in% 1,])
)

ItemsList <- venn(lista, show.plot = FALSE)
ItemsList
attributes(ItemsList)$intersections
lista

library("VennDiagram")
venn.diagram(lista)
overlap <- calculate.overlap(x = lista)
calculate.overlap()

# lista confusion matrices
ConMat_list <- list()
for (i in 1:(ncol(CodPot_res_tab))) {
  ConMat_list[[paste0(colnames(CodPot_res_tab)[i])]] <-
    confusionMatrix(data = as.factor(CodPot_res_tab[,i]), as.factor(confirmed_lnc))
}
ConMat_list
length(ConMat_list)


# 4. i jeszcze jedno podejscie trzeba zrobic, czyli ML zrobic profil przewidywania (0,1) lub (probability) i
# na podstawie danych z bazy nauczyc model i potem zrobic przewidywanie dla nowych daych
# dokladnie tak, jak bylo robione dla policji rok temu.

# ///////////////////////////////////





class(CodPot_res_tab)
head(CodPot_res_tab)

ifelse(rowSums(dane) >= 0, 1, 0)
ifelse(rowSums(dane) > 1, 1, 0)
ifelse(rowSums(dane) > 2, 1, 0)
ifelse(rowSums(dane) > 3, 1, 0)
ifelse(rowSums(dane) > 4, 1, 0)
ifelse(rowSums(dane) >= 7, 1, 0)




CPC2 <- confusionMatrix(data = as.factor(dane$CPC2), as.factor(dane$lnc))
CPC2$overall
CPC2$table
CPC2$positive
CPC2$byClass

class(CPC2)

# 1. wszystkie przypadki
# 2. ML szukaj wg profilu dokladnie jak w tym dla policji

ConMat <- confusionMatrix(data = as.factor(dane[,1]), as.factor(dane$lnc))

list(CPC2 = ConMat)



ConMat_list <- list()
for (i in 1:(ncol(dane)-1)) {
  ConMat_list[[paste0(colnames(dane)[i])]] <- confusionMatrix(data = as.factor(dane[,i]), as.factor(dane$lnc))
}
ConMat_list

ConMat_list$CPC2$overall



list(colnames(dane))


x <- list()
for(i in 1:N) {
  Ps <- i  ## where i is whatever your Ps is
  x[[paste0("element", i)]] <- Ps
}
x



N <- 3
x <- vector("list", N)
for(i in 1:N) {
  Ps <- i  ## where i is whatever your Ps is
  x[[i]] <- Ps
}
setNames(x, paste0("element", 1:N))



# //////////////////////
# cutpointr
# https://github.com/Thie1e/cutpointr
install.packages("cutpointr")

library(cutpointr)

data(suicide)
head(suicide)
table(suicide$suicide)
table(suicide$dsi)

cp <- cutpointr(suicide, dsi, suicide,
                method = maximize_metric, metric = sum_sens_spec)
summary(cp)
head(cp)
